{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7a6db16-8bfd-42e3-a9d4-dbd64f8c84d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import time\n",
    "import tracemalloc \n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1791b0f5-02da-4cd1-a588-6701554f16b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage is 1.660835MB; Peak was 3.761753MB\n",
      "\n",
      "Training Time : 3.312140\n",
      "Testing Time : 0.015958\n",
      "============== wine datasets ================\n",
      "training accuracy : 0.960\n",
      "Testing Accuracy :  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    " # get the dataset\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "def get_dataset():\n",
    "    X, y = load_wine(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    # X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X_train, y_train\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [100]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "start_training = time.time()\n",
    "tracemalloc.start()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the wayprint('wine datasets')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory() \n",
    "end_training = time.time()\n",
    "\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\\n\") \n",
    "print('Training Time : %f' %(end_training - start_training))\n",
    "\n",
    "start_testing = time.time()\n",
    "testing = model.predict(X_test)\n",
    "end_testing = time.time()\n",
    "\n",
    "print('Testing Time : %f' %(end_testing - start_testing))\n",
    "print(\"============== wine datasets ================\")\n",
    "print('training accuracy : %.3f' % ( mean(scores)))\n",
    "print(\"Testing Accuracy : \",(y_test == testing).sum()/X_test.shape[0])\n",
    "# plot model performance for comparison\n",
    "# pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61e6315c-b0a5-4a20-a254-1e84858d9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage is 1.829751MB; Peak was 3.761753MB\n",
      "\n",
      "Training Time : 3.704092\n",
      "Testing Time : 0.034906\n",
      "============== car datasets ================\n",
      "accuracy : 0.956\n",
      "Testing Accuracy :  0.9490740740740741\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/car.data', encoding = 'utf-8',header = None)\n",
    "data.columns.tolist()\n",
    "data.rename(columns = {0:'buying',1:'maintainence',2:'doors',3:'persons',4:'lug_boot',5:'safety',6:'class'},inplace = True)\n",
    "data['class'].value_counts()\n",
    "cleanup_nums = {\"class\":     {\"unacc\": 4, \"acc\": 3,'good': 2,'vgood':1}\n",
    "                }\n",
    "data.replace(cleanup_nums,inplace = True)\n",
    "data['class'].value_counts()\n",
    "target = data['class']\n",
    "data.drop( ['class'],axis = 1,inplace = True)\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=0)\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    data = pd.read_csv('./datasets/car.data', encoding = 'utf-8',header = None)\n",
    "    data.columns.tolist()\n",
    "    data.rename(columns = {0:'buying',1:'maintainence',2:'doors',3:'persons',4:'lug_boot',5:'safety',6:'class'},inplace = True)\n",
    "    data['class'].value_counts()\n",
    "    cleanup_nums = {\"class\":     {\"unacc\": 4, \"acc\": 3,'good': 2,'vgood':1}\n",
    "                }\n",
    "    data.replace(cleanup_nums,inplace = True)\n",
    "    data['class'].value_counts()\n",
    "    target = data['class']\n",
    "    data.drop( ['class'],axis = 1,inplace = True)\n",
    "    data = pd.get_dummies(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state=0)\n",
    "    # X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X_train, y_train\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [100]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "start_training = time.time()\n",
    "tracemalloc.start()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the wayprint('wine datasets')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory() \n",
    "end_training = time.time()\n",
    "\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\\n\") \n",
    "print('Training Time : %f' %(end_training - start_training))\n",
    "\n",
    "start_testing = time.time()\n",
    "testing = model.predict(X_test)\n",
    "end_testing = time.time()\n",
    "\n",
    "print('Testing Time : %f' %(end_testing - start_testing))\n",
    "print(\"============== car datasets ================\")\n",
    "print('accuracy : %.3f' % ( mean(scores)))\n",
    "print(\"Testing Accuracy : \",(y_test == testing).sum()/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1af1c35f-2870-42d5-8eb2-4bc8d4ae2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage is 1.734978MB; Peak was 3.761753MB\n",
      "\n",
      "Training Time : 2.785924\n",
      "Testing Time : 0.016956\n",
      "============== iris datasets ================\n",
      "training accuracy : 0.949\n",
      "Testing Accuracy :  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# get the dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "def get_dataset():\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    # X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X_train, y_train\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [100]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "start_training = time.time()\n",
    "tracemalloc.start()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the wayprint('wine datasets')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory() \n",
    "end_training = time.time()\n",
    "\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\\n\") \n",
    "print('Training Time : %f' %(end_training - start_training))\n",
    "\n",
    "start_testing = time.time()\n",
    "testing = model.predict(X_test)\n",
    "end_testing = time.time()\n",
    "\n",
    "print('Testing Time : %f' %(end_testing - start_testing))\n",
    "print(\"============== iris datasets ================\")\n",
    "print('training accuracy : %.3f' % ( mean(scores)))\n",
    "print(\"Testing Accuracy : \",(y_test == testing).sum()/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fdb467d-0805-418d-9b69-c519629933b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage is 2.075012MB; Peak was 3.761753MB\n",
      "\n",
      "Training Time : 21.029739\n",
      "Testing Time : 0.014958\n",
      "============== wine quality ================\n",
      "training accuracy : 0.870\n",
      "Testing Accuracy :  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    df=pd.read_csv(\"./datasets/winequality_W.csv\")\n",
    "    df = df.fillna(value=0)\n",
    "    df['Quality']=0\n",
    "    df.loc[df['quality']>6, 'Quality']=1\n",
    "    df.drop('quality', axis=1, inplace=True)\n",
    "    data = df.drop('Quality', axis=1).drop('type', axis=1)\n",
    "    target = df['Quality']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)\n",
    "    # X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    return X_train, y_train\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [100]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "start_training = time.time()\n",
    "tracemalloc.start()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the wayprint('wine datasets')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory() \n",
    "end_training = time.time()\n",
    "\n",
    "print(f\"Current memory usage is {current / 10**6}MB; Peak was {peak / 10**6}MB\\n\") \n",
    "print('Training Time : %f' %(end_training - start_training))\n",
    "\n",
    "start_testing = time.time()\n",
    "testing = model.predict(X_test)\n",
    "end_testing = time.time()\n",
    "\n",
    "print('Testing Time : %f' %(end_testing - start_testing))\n",
    "print(\"============== wine quality ================\")\n",
    "print('training accuracy : %.3f' % ( mean(scores)))\n",
    "print(\"Testing Accuracy : \",(y_test == testing).sum()/X_test.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
